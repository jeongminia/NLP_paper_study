{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOOWOLC1PvppEL1CVR44v0/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["https://github.com/hyona-yu/python_machine_learning/blob/main/rnn_python.ipynb"],"metadata":{"id":"pfQiYHoInZFF"}},{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"H_o8KHDDneOt","executionInfo":{"status":"ok","timestamp":1720916515859,"user_tz":-540,"elapsed":351,"user":{"displayName":"Jeongmin Ahn","userId":"13913237267246789835"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":17,"metadata":{"id":"B3Gxrvi_nRPW","executionInfo":{"status":"ok","timestamp":1720916914721,"user_tz":-540,"elapsed":333,"user":{"displayName":"Jeongmin Ahn","userId":"13913237267246789835"}}},"outputs":[],"source":["class Softmax: # 출력층 상태 계산을 위함\n","    def __call__(self, x):\n","        exps = np.exp(x)\n","        self._softmax = exps / np.sum(exps)\n","        return self._softmax\n","\n","class Sigmoid: # 은닉층 상태 계산을 위함\n","    def __call__(self, x):\n","        exps = np.exp(x)\n","        self._sigmoid = exps / (1 + exps)\n","        return self._sigmoid\n","\n","    def derivative(self):\n","        return self._sigmoid * (1-self._sigmoid)\n","\n","# 성능평가 : RNN에서 특정 예측 모델의 성능을 평가할 때 사용될 수 있는 손실 함수와 그에 대한 미분을 정의\n","class MSELoss:\n","    def __call__(self, preds, labels):\n","        self._loss = np.square(preds - labels)\n","        return np.mean(self._loss)\n","\n","    def derivative(self):\n","        return np.sqrt(self._loss) * (-1/2)"]},{"cell_type":"markdown","source":["`tanh` 출력값 계산시, 가중치 벡터와 함께 계산됨"],"metadata":{"id":"oq4qJ9BmoZUW"}},{"cell_type":"code","source":["def tanh(x):\n","    exp_minus = np.exp(-1 * x)\n","    exp_plus = np.exp(x)\n","    return (exp_plus + exp_minus) / (exp_plus + exp_minus)"],"metadata":{"id":"o_XxCdehoESG","executionInfo":{"status":"ok","timestamp":1720916915536,"user_tz":-540,"elapsed":477,"user":{"displayName":"Jeongmin Ahn","userId":"13913237267246789835"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["class Tanh: # tanh 함수의 미분은 클래스로 표현\n","    def __call__(self,x):\n","        exp_minus = np.exp(-1 * x)\n","        exp_plus = np.exp(x)\n","        self.tanh = (exp_plus + exp_minus) / (exp_plus + exp_minus)\n","        return self.tanh\n","\n","    def derivative(self):\n","        return (1+self.tanh) * (1-self.tanh)"],"metadata":{"id":"_jxnPwX-oPjk","executionInfo":{"status":"ok","timestamp":1720916915536,"user_tz":-540,"elapsed":1,"user":{"displayName":"Jeongmin Ahn","userId":"13913237267246789835"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["class PReLU:\n","    def __init__(self, a=0.25):\n","        self.a = a\n","\n","    def __call__(self, x):\n","        zeros = np.zeros(x.shape)\n","        self._z = np.max([zeros, x], axis = 0) + self.a * np.min([zeros, x], axis = 0)\n","        return self._z\n","\n","    def derivative(self):\n","        x, y = self._z.shape\n","        zeros = np.zeros((x,y))\n","        for i in range(x):\n","            for j in range(y):\n","                if self._z[i][j] >0:\n","                    zeros[i][j] = 1\n","                elif self._z[i][j] <0:\n","                    zeros[i][j] =  -self.a\n","        return zeros"],"metadata":{"id":"hwZDmLg3oPhP","executionInfo":{"status":"ok","timestamp":1720916915536,"user_tz":-540,"elapsed":1,"user":{"displayName":"Jeongmin Ahn","userId":"13913237267246789835"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def PReLU(x, a = 0.25):\n","    zeros = np.zeros(x.shape)\n","    return np.max([zeros, x], axis = 0) + a * np.min([zeros, x], axis = 0)"],"metadata":{"id":"Jbe1iG0uoUkz","executionInfo":{"status":"ok","timestamp":1720916916000,"user_tz":-540,"elapsed":2,"user":{"displayName":"Jeongmin Ahn","userId":"13913237267246789835"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["class SimpleRNN:\n","    def __init__(self, input_shape, hidden_dim, h=None, act_fn='tanh'):\n","        self.batch_size, self.length, self.embedding_size = input_shape\n","        self.weight, self.bias = [], []\n","        self.hidden_dim = hidden_dim\n","\n","        if act_fn=='tanh':\n","            self.act_fn = Tanh()\n","\n","        elif act_fn=='sigmoid':\n","            self.act_fn = Sigmoid()\n","\n","        # hidden h 가 없을 경우 0으로 초기화\n","        if h is None:\n","            self.h = np.zeros((self.batch_size, self.length+1, hidden_dim))\n","        else:\n","            self.h = h\n","\n","        for i in range(self.length):\n","            self.in_size = self.embedding_size\n","            w_h = np.random.rand(self.hidden_dim, self.hidden_dim)\n","            w_x = np.random.rand(self.in_size, self.hidden_dim)\n","            weight = np.concatenate((w_h, w_x), axis= 0) #(self.in_size+hidden_dim , hidden_dim )\n","            self.weight.append(weight)\n","            self.bias.append(np.random.rand(self.hidden_dim))\n","\n","    def __call__(self, x):\n","        next_x = x[0]\n","        outs = []\n","        for t in range(self.length):\n","            out = np.matmul(np.concatenate((self.h[:,t,:], x[:,t,:]),axis=1),self.weight[t]) + self.bias[t]\n","            self.h[:,t+1,:] = out[:self.hidden_dim,:] # 다음 스텝에서 h_(t)역할을 해줄 것.\n","            real_out = out[self.hidden_dim:,:]\n","            real_out = self.act_fn(out) #활성화함수\n","            outs.append(real_out)\n","\n","        outs = np.array(outs) # shape (length, batch_size, hidden_dim)\n","        outs = np.transpose(outs, (1,0,2))\n","        return self.h[:,1:], outs"],"metadata":{"id":"S6Sc90liohug","executionInfo":{"status":"ok","timestamp":1720916916001,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jeongmin Ahn","userId":"13913237267246789835"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["x = [[[1,2,3,4], [3,4,5,6], [4,5,6,7]], [[3,4,1,1], [4,5,1,1], [5,6,1,1]]]\n","x = np.array(x)\n","y = [[0], [1]]\n","y = np.array(y)\n","x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wfqH__rIojqO","executionInfo":{"status":"ok","timestamp":1720916916001,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jeongmin Ahn","userId":"13913237267246789835"}},"outputId":"98db783c-6344-43fc-9b41-bfba133e8713"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2, 3, 4)"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["batch_size 2, timestamp_length 3, embedding_size 4"],"metadata":{"id":"ehcEinAWop_s"}},{"cell_type":"code","source":["layer = SimpleRNN(x.shape, 8, h=None)\n","layer(x)[0].shape, layer(x)[1].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xyeJi0P7onWn","executionInfo":{"status":"ok","timestamp":1720916916533,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jeongmin Ahn","userId":"13913237267246789835"}},"outputId":"95b97b70-f50c-41ee-b464-0f93555889bb"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((2, 3, 8), (2, 3, 8))"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["class RNN:\n","    def __init__(self, input_shape, hidden_dim, h=None, act_fn='Tanh'):\n","        self.batch_size, self.length, self.embedding_size = input_shape\n","        self.weight, self.bias = [], []\n","        self.hidden_dim = hidden_dim\n","\n","        if act_fn=='Tanh':\n","            self.act_fn = Tanh()\n","\n","        elif act_fn=='Sigmoid':\n","            self.act_fn = Sigmoid()\n","\n","        if h is None:\n","            self.h = np.zeros((self.batch_size, self.length+1, hidden_dim))\n","        else:\n","            self.h = h\n","\n","        for i in range(self.length):\n","            self.in_size = self.embedding_size\n","            w_h = np.random.rand(self.hidden_dim, self.hidden_dim)\n","            w_x = np.random.rand(self.in_size, self.hidden_dim)\n","            weight = np.concatenate((w_h, w_x), axis= 0) #(self.in_size+hidden_dim , hidden_dim )\n","            self.weight.append(weight)\n","            self.bias.append(np.random.rand(self.hidden_dim))\n","\n","    def __call__(self, x, h =None):\n","        next_x = x[0]\n","        if h is not None:\n","            self.h = h\n","        outs = []\n","        for t in range(self.length):\n","            print(f'{t}th timestamp, x[t] shape {x[:,t,:].shape}, h[t] shape {self.h[:,t,:].shape}, self.weight[t] shape {self.weight[t].shape}')\n","            new_x = np.concatenate((self.h[:,t,:], x[:,t,:]),axis=1)\n","            print(f'new_x shape {new_x.shape} bias shape {self.bias[t].shape}')\n","            out = np.matmul(new_x,self.weight[t]) + self.bias[t]\n","            self.h[:,t+1,:] = out[:self.hidden_dim,:] # 다음 스텝에서 h_(t)역할을 해줄 것.\n","            real_out = out[self.hidden_dim:,:]\n","            real_out = self.act_fn(out) #활성화함수\n","            outs.append(real_out)\n","\n","        outs = np.array(outs) # shape (length, batch_size, hidden_dim)\n","        outs = np.transpose(outs, (1,0,2))\n","        return outs\n","\n","    #backpropagation 함수 추가.\n","    def backpropagation(self, x, z, learning_rate):\n","        dz_dy = self.act_fn.derivative()\n","        for l in reversed(range(self.length)): #timestamp만큼의 RNN 노드가 있다. l번째 weight, bias를 순서대로 역전파 계산하자.\n","            dy_dw = np.concatenate((self.h[:,l,:], x[:,l,:]), axis=-1) #(batch_size, 1, self.embedding_size + self.in_size)\n","            #print(f'dy_dw shape {dy_dw.shape}')\n","            dy_db = 1\n","            dz_dw = np.matmul(np.transpose(dy_dw), dz_dy)\n","            #print(f'dz_dw shape { dz_dw.shape}')\n","            dz_db = dz_dy * dy_db\n","            self.weight[l] = self.weight[l] + learning_rate * dz_dw\n","            self.bias[l] = self.bias[l] + learning_rate * dz_db"],"metadata":{"id":"AWvDTXIRpp_z","executionInfo":{"status":"ok","timestamp":1720917288979,"user_tz":-540,"elapsed":342,"user":{"displayName":"Jeongmin Ahn","userId":"13913237267246789835"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["layer = RNN(x.shape, 8, h=None)"],"metadata":{"id":"xdVpjM-6pp9G","executionInfo":{"status":"ok","timestamp":1720917290577,"user_tz":-540,"elapsed":2,"user":{"displayName":"Jeongmin Ahn","userId":"13913237267246789835"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["x = [[[1,2,3,4], [3,4,5,6], [4,5,6,7]], [[3,4,1,1], [4,5,1,1], [5,6,1,1]]]\n","y = [[0], [1]]\n","x = np.array(x)\n","y = np.array(y)\n","x.shape, y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rla0fVhmpzcw","executionInfo":{"status":"ok","timestamp":1720918649096,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jeongmin Ahn","userId":"13913237267246789835"}},"outputId":"51c44029-306f-4d43-bd67-850e19001711"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((2, 3, 4), (2, 1))"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","source":["## RNN 학습하는 train 클래스"],"metadata":{"id":"TWKazNPdqjVx"}},{"cell_type":"code","source":["class Train: # 레이어 3개 쌓은 형태\n","    def __init__(self, x, y, n_layers =3, n_node = 32, epochs=10, learning_rate=1e-3):\n","        self.epochs = epochs\n","        self.learning_rate = learning_rate\n","        self.layers = []\n","        self.loss_fcn = MSELoss()\n","        self.n_layers = n_layers # RNN 층의 수\n","        self.batch_size, self.length, self.embedding_size = x.shape\n","\n","        for i in range(n_layers):\n","            act_fn = 'Tanh'\n","            out_shape = n_node\n","\n","            if i != 0: #첫번째 레이어\n","                self.embedding_size = n_node\n","\n","            if i == n_layers-1: #마지막 레이어\n","                out_shape = y.shape[-1]\n","                act_fn = 'Sigmoid'\n","\n","            print(f'{i}th layer input_shape({self.batch_size, self.length,self.embedding_size},hidden dim {out_shape})')\n","            self.layers.append(RNN(input_shape=(self.batch_size,self.length,self.embedding_size), hidden_dim=out_shape, h = None, act_fn=act_fn))\n","\n","        self._train(x, y)\n","\n","    def _forward(self, x):\n","        outs = []\n","        new_x = x\n","        for layer in self.layers:\n","            #이전 layer의 output값인 hidden layer를 넣어보자.\n","            new_x  = layer(new_x)\n","            outs.append(new_x)\n","\n","        return outs, new_x #outs에는 지금까지 layer들의 출력값이 담겨있다.\n","\n","    def _backpropagation(self, x, outs, loss, learning_rate):\n","        for i in reversed(range(self.n_layers)):\n","            if i == 0:\n","                x_in = x\n","            else:\n","                x_in = outs[i-1]\n","            if i == self.n_layers - 1:\n","                outs[i] = outs[i] * np.mean(self.loss_fcn.derivative())\n","            self.layers[i].backpropagation(x_in, outs[i], learning_rate)\n","\n","        #    def backpropagation(self, x, z, learning_rate):\n","\n","    def _train(self, x, y):\n","        for e in range(self.epochs):\n","            outs, out = self._forward(x)\n","            real_out = out[:,-1,:] #마지막 timestamp의 값을 가져온다.\n","            loss = self.loss_fcn(real_out, y)\n","            #outs.append(loss) #각 layer의 역전파를 위해 쓰일 배열이다.\n","            self._backpropagation(x, outs, loss, self.learning_rate)\n","\n","            print(f'{e+1}번째 epoch의 loss는 {loss}')"],"metadata":{"id":"HbVharWDooV9","executionInfo":{"status":"ok","timestamp":1720917291602,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jeongmin Ahn","userId":"13913237267246789835"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["train = Train\n","train(x,y, n_node=8)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s6Zs-ayao4L5","executionInfo":{"status":"ok","timestamp":1720917292765,"user_tz":-540,"elapsed":5,"user":{"displayName":"Jeongmin Ahn","userId":"13913237267246789835"}},"outputId":"d728af6a-a7ea-47d8-8ce5-9e7c631865b1"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["0th layer input_shape((2, 3, 4),hidden dim 8)\n","1th layer input_shape((2, 3, 8),hidden dim 8)\n","2th layer input_shape((2, 3, 8),hidden dim 1)\n","0th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (8,)\n","1th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (8,)\n","2th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (8,)\n","0th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (8,)\n","1th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (8,)\n","2th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (8,)\n","0th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (1,)\n","1th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (1,)\n","2th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (1,)\n","1번째 epoch의 loss는 0.4991619135855374\n","0th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","1th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","2th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","0th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","1th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","2th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","0th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","1th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","2th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","2번째 epoch의 loss는 0.4991619860658918\n","0th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","1th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","2th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","0th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","1th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","2th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","0th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","1th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","2th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","3번째 epoch의 loss는 0.4991620585344273\n","0th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","1th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","2th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","0th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","1th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","2th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","0th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","1th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","2th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","4번째 epoch의 loss는 0.4991621309911466\n","0th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","1th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","2th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","0th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","1th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","2th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","0th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","1th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","2th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","5번째 epoch의 loss는 0.49916220343605266\n","0th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","1th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","2th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","0th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","1th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","2th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","0th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","1th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","2th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","6번째 epoch의 loss는 0.4991622758691483\n","0th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","1th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","2th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","0th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","1th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","2th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","0th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","1th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","2th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","7번째 epoch의 loss는 0.49916234829043626\n","0th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","1th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","2th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","0th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","1th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","2th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","0th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","1th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","2th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","8번째 epoch의 loss는 0.49916242069991945\n","0th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","1th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","2th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","0th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","1th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","2th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","0th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","1th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","2th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","9번째 epoch의 loss는 0.49916249309760086\n","0th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","1th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","2th timestamp, x[t] shape (2, 4), h[t] shape (2, 8), self.weight[t] shape (12, 8)\n","new_x shape (2, 12) bias shape (2, 8)\n","0th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","1th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","2th timestamp, x[t] shape (2, 8), h[t] shape (2, 8), self.weight[t] shape (16, 8)\n","new_x shape (2, 16) bias shape (2, 8)\n","0th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","1th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","2th timestamp, x[t] shape (2, 8), h[t] shape (2, 1), self.weight[t] shape (9, 1)\n","new_x shape (2, 9) bias shape (2, 1)\n","10번째 epoch의 loss는 0.4991625654834829\n"]},{"output_type":"execute_result","data":{"text/plain":["<__main__.Train at 0x7cafd4ae9ae0>"]},"metadata":{},"execution_count":39}]}]}